{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Forecasting\n",
    "Can you forecast the demand of the car rentals on an hourly basis?\n",
    "\n",
    "\n",
    "#### Problem Statement\n",
    "ABC is a car rental company based out of Bangalore. It rents cars for both in and out stations at affordable prices. The users can rent different types of cars like Sedans, Hatchbacks, SUVs and MUVs, Minivans and so on.\n",
    "\n",
    "In recent times, the demand for cars is on the rise. As a result, the company would like to tackle the problem of supply and demand. The ultimate goal of the company is to strike the balance between the supply and demand inorder to meet the user expectations. \n",
    "\n",
    "The company has collected the details of each rental. Based on the past data, the company would like to forecast the demand of car rentals on an hourly basis. \n",
    "\n",
    "\n",
    "#### Objective\n",
    "The main objective of the problem is to develop the machine learning approach to forecast the demand of car rentals on an hourly basis.\n",
    "\n",
    "\n",
    "#### Data Dictionary\n",
    "You are provided with 3 files - train.csv, test.csv and sample_submission.csv\n",
    "\n",
    "Training set\n",
    "\n",
    "train.csv contains the hourly demand of car rentals from August 2018 to February 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "## import important librabries:\n",
    "import plotly.express as px\n",
    "import numpy as np, pandas as pd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import TimeSeriesSplit,GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from glmnet import ElasticNet as glm_elastic\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import xgboost as xgb\n",
    "from fbprophet import Prophet\n",
    "\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import adam_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_E1GspfA.csv\")\n",
    "test_df = pd.read_csv(\"test_6QvDdzb.csv\")\n",
    "sub_df = pd.read_csv(\"sample_4E0BhPN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour  demand\n",
       "0  2018-08-18     9      91\n",
       "1  2018-08-18    10      21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fb Prohpet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hour(dt,hr):\n",
    "    return dt  + datetime.timedelta(hours = hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['date'] = train_df.apply(lambda row: add_hour(row['date'],row['hour']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_train_df = train_df[['date','demand']]\n",
    "fb_train_df.columns = ['ds','y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "train = fb_train_df.iloc[:-1000]\n",
    "test = fb_train_df.iloc[-1000:]\n",
    "fb_m = Prophet()\n",
    "fb_m.fit(train)\n",
    "\n",
    "y_pred = fb_m.predict(fb_m.make_future_dataframe(\n",
    "    periods=1000,freq = 'H'))[['yhat_lower', 'yhat','yhat_upper']][-1000::]\n",
    "\n",
    "print(rmse(test['y'],y_pred['yhat'].astype('int')))\n",
    "print(\"with dec\",rmse(test['y'],y_pred['yhat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update test_df\n",
    "test_fb_df = test_df.copy()\n",
    "test_df['date'] = test_df.apply(lambda row: add_hour(row['date'],\n",
    "                                                       row['hour']),axis=1)\n",
    "\n",
    "# apply model and make prediction\n",
    "full_pred = fb_m.predict(fb_m.make_future_dataframe(\n",
    "    periods=11000,freq = 'H'))[['ds','yhat_lower', 'yhat','yhat_upper']]\n",
    "\n",
    "# takeout predicted values and save\n",
    "demand_pred = full_pred[full_pred['ds'].isin(test_df['date'].values)]['yhat']\n",
    "sub_df['demand'] = demand_pred.values\n",
    "sub_df.to_csv('sub_fb_prpht.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_m_final = Prophet()\n",
    "fb_m_final.fit(fb_train_df)\n",
    "\n",
    "y_pred_full = fb_m_final.predict(fb_m_final.make_future_dataframe(\n",
    "    periods=10000,freq = 'H'))[['ds','yhat_lower', 'yhat','yhat_upper']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_pred_with_final_model = y_pred_full[y_pred_full['ds'].isin(test_df['date'].values)]['yhat']\n",
    "sub_df['demand'] = demand_pred_with_final_model.values\n",
    "sub_df.to_csv('sub_fb_prpht_full.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update test_df\n",
    "test_fb_df = test_df.copy()\n",
    "test_df['date'] = test_df.apply(lambda row: add_hour(row['date'],\n",
    "                                                       row['hour']),axis=1)\n",
    "\n",
    "# apply model and make prediction\n",
    "full_pred = fb_m.predict(fb_m.make_future_dataframe(\n",
    "    periods=11000,freq = 'H'))[['ds','yhat_lower', 'yhat','yhat_upper']]\n",
    "\n",
    "# takeout predicted values and save\n",
    "demand_pred = full_pred[full_pred['ds'].isin(test_df['date'].values)]['yhat']\n",
    "sub_df['demand'] = demand_pred.values\n",
    "sub_df.to_csv('sub_fb_prpht.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.assign(\"check\",test_df['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['demand'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['demand'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt['12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tt.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily demand summing up all the hours in the day\n",
    "# fig = px.line(train_df.groupby(['date'])['demand'].sum().reset_index(), x=\"date\", y=\"demand\")\n",
    "# fig.show()\n",
    "\n",
    "# mean daily demand \n",
    "# fig = px.line(train_df.groupby(['date'])['demand'].mean().reset_index(), x=\"date\", y=\"demand\")\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# mean hourly demand\n",
    "# fig = px.line(train_df.groupby(['hour'])['demand'].mean().reset_index(), x=\"hour\", y=\"demand\")\n",
    "# fig = px.line(train_df.groupby(['hour'])['demand'].max().reset_index(), x=\"hour\", y=\"demand\")\n",
    "# fig = px.line(train_df.groupby(['hour'])['demand'].min().reset_index(), x=\"hour\", y=\"demand\")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# plot_acf(train_df[\"demand\"]);\n",
    "# plot_pacf(train_df[\"demand\"]);\n",
    "\n",
    "\n",
    "# print(\"Observations of Dickey-fuller test\")\n",
    "# dftest = adfuller(train_df['demand'],autolag='AIC')\n",
    "# dfoutput=pd.Series(dftest[0:4],index=['Test Statistic','p-value','#lags used','number of observations used'])\n",
    "# for key,value in dftest[4].items():\n",
    "#     dfoutput['critical value (%s)'%key]= value\n",
    "# print(dfoutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_date_feats(df):\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['week'] = df['date'].dt.week\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['is_weekend'] = np.where(df['day_of_week'].isin([5,6]),1,0)\n",
    "    df['is_weekday'] = np.where(df['day_of_week'].isin([0,1,2,3,4]),1,0)\n",
    "    df['days_in_month'] = df['date'].dt.days_in_month\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_lag_feats(df,num_of_lags=4):\n",
    "    df = df.copy()\n",
    "    for lag in range(1,num_of_lags+1):\n",
    "        df[\"demand_lag_0\" + str(lag)] = df['demand'].shift(lag).fillna(method = 'bfill')\n",
    "    return df\n",
    "\n",
    "def feat_engg(df):\n",
    "    df = df.copy()\n",
    "    df = get_date_feats(df)\n",
    "#     df = get_lag_feats(df,4)\n",
    "    return df\n",
    "\n",
    "def rmse(actual,forecast):\n",
    "    return np.mean((forecast - actual)**2)**.5  # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8838278540ff>:5: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df['week'] = df['date'].dt.week\n",
      "<ipython-input-5-8838278540ff>:5: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df['week'] = df['date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "train_df = feat_engg(train_df)\n",
    "test_df = feat_engg(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>days_in_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  hour  month  week  ...  quarter  is_weekend  is_weekday  days_in_month\n",
       "0 2021-03-01     0      3     9  ...        1           0           1             31\n",
       "1 2021-03-01     1      3     9  ...        1           0           1             31\n",
       "\n",
       "[2 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'hour', 'demand', 'month', 'week', 'year', 'day_of_week',\n",
       "       'day_of_year', 'quarter', 'is_weekend', 'is_weekday', 'days_in_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_model = ['hour', 'month', 'week', 'year', 'day_of_week',\n",
    "       'day_of_year', 'quarter', 'is_weekend', 'is_weekday', 'days_in_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>demand</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>days_in_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  hour  demand  ...  is_weekend  is_weekday  days_in_month\n",
       "0 2018-08-18     9      91  ...           1           0             31\n",
       "1 2018-08-18    10      21  ...           1           0             31\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started\n",
      "params {'alpha': 1} -40.47946295846964\n",
      "Run started\n",
      "params {'alpha': 0.7} -40.47123243002248\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=2\n",
    "                       ,test_size=500)\n",
    "X = train_df[cols_for_model]\n",
    "Y = train_df[\"demand\"]\n",
    "\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "#     y_train, y_test = Y.iloc[list(train_index)], Y.iloc[list(test_index)]\n",
    "#     # Build Model\n",
    "#     st = StandardScaler()\n",
    "#     st.fit(X_train)\n",
    "#     X_train = st.transform(X_train)\n",
    "#     X_test = st.transform(X_test)\n",
    "#     my_lr = ElasticNet()\n",
    "#     my_lr.fit(X_train, y_train)\n",
    "#     y_pred = my_lr.predict(X_test)\n",
    "#     print(rmse(y_test,y_pred))\n",
    "    \n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "#     y_train, y_test = Y.iloc[list(train_index)], Y.iloc[list(test_index)]\n",
    "#     # Build Model\n",
    "#     rfr = RandomForestRegressor()\n",
    "#     rfr.fit(X_train, y_train)\n",
    "#     y_pred = rfr.predict(X_test)\n",
    "#     print(rmse(y_test,y_pred))\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "    y_train, y_test = Y.iloc[list(train_index)], Y.iloc[list(test_index)]\n",
    "    # Build Model\n",
    "    st = StandardScaler()\n",
    "    st.fit(X_train)\n",
    "    X_train = st.transform(X_train)\n",
    "    X_test = st.transform(X_test)\n",
    "    \n",
    "    print(\"Run started\")\n",
    "    params = {\"alpha\"    : [0.1, 0.3, 0.5,0.7,0.9,1]}\n",
    "\n",
    "    gsearch1 = GridSearchCV(estimator = glm_elastic(),param_grid = params, \n",
    "                            scoring='neg_root_mean_squared_error',n_jobs=4, cv=5)\n",
    "    gsearch1.fit(X_train,y_train)\n",
    "    print(\"params\", gsearch1.best_params_, gsearch1.best_score_)\n",
    "    \n",
    "    \n",
    "#     glm = glm_elastic(alpha = 0.3)\n",
    "#     glm.fit(X_train, y_train)\n",
    "    \n",
    "#     y_pred_train = glm.predict(X_train)\n",
    "#     print(\"train RMSE\",rmse(y_train,y_pred_train))\n",
    "    \n",
    "#     y_pred = glm.predict(X_test)\n",
    "#     print(\"test RMSE\",rmse(y_test,y_pred))\n",
    "    \n",
    "\n",
    "\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "#     y_train, y_test = Y.iloc[list(train_index)], Y.iloc[list(test_index)]\n",
    "#     # Build Model\n",
    "#     dtree = DecisionTreeRegressor()\n",
    "#     dtree.fit(X_train, y_train)\n",
    "#     y_pred = dtree.predict(X_test)\n",
    "#     print(rmse(y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# # XGB Model\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "#     y_train, y_test = Y.iloc[list(train_index)], Y.iloc[list(test_index)]\n",
    "# #     Build Model\n",
    "#     st = StandardScaler()\n",
    "#     st.fit(X_train)\n",
    "#     X_train = st.transform(X_train)\n",
    "#     X_test = st.transform(X_test)\n",
    "\n",
    "# #     print(\"Run started\")\n",
    "# #     params = {\"learning_rate\"    : [0.05, 0.10, 0.15] , \n",
    "# #               \"max_depth\"        : [ 3, 4, 5, 6],\n",
    "# #              \"min_child_weight\" : [ 1, 3 ],\n",
    "# #              \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "# #              \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\n",
    "\n",
    "# #     gsearch1 = GridSearchCV(estimator = xgb.XGBRegressor(n_estimators=50,\n",
    "# #                                                       subsample=0.8,\n",
    "# #                                                       seed=0),param_grid = params, \n",
    "# #                             scoring='neg_root_mean_squared_error',n_jobs=4, cv=5)\n",
    "# #     gsearch1.fit(X_train,y_train)\n",
    "# #     print(\"params\", gsearch1.best_params_, gsearch1.best_score_)\n",
    "\n",
    "    \n",
    "    \n",
    "#     xgm = xgb.XGBRegressor(n_estimators=50,subsample=0.8,\n",
    "#                            colsample_bytree= 0.5,\n",
    "#                         gamma = 0.0,learning_rate = 0.1,\n",
    "#                         max_depth = 3,\n",
    "#                         min_child_weight = 1)\n",
    "#     xgm.fit(X_train, y_train)\n",
    "    \n",
    "#     y_pred_train = xgm.predict(X_train)\n",
    "#     print(\"train RMSE; \",rmse(y_train,y_pred_train))\n",
    "    \n",
    "#     y_pred = xgm.predict(X_test)\n",
    "#     print(\"test RMSE: \",rmse(y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Use nn:\n",
    "\n",
    "# # define model\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "#     y_train, y_test = Y.iloc[list(train_index)], Y.iloc[list(test_index)]\n",
    "#     # Build Model\n",
    "#     X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1]))\n",
    "#     X_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1]))\n",
    "#     print(X_train.shape,X_test.shape)\n",
    "#     nn_model = Sequential()\n",
    "#     nn_model.add(Dense(12, activation='relu'))\n",
    "#     nn_model.add(Dense(10))\n",
    "#     nn_model.add(Dense(1))\n",
    "#     nn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
    "#     nn_model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1, callbacks=[early_stop], shuffle=False)\n",
    "#     y_pred = nn_model.predict(X_test)\n",
    "#     y_pred = np.array([y_pred[i][0] for i in range(len(y_pred)) ])\n",
    "#     print(\"RMSE Score is\",rmse(y_test,y_pred))\n",
    "\n",
    "    \n",
    "# # define LSTM model\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "#     y_train, y_test = Y.iloc[list(train_index)], Y.iloc[list(test_index)]\n",
    "#     st = StandardScaler()\n",
    "#     st.fit(X_train)\n",
    "#     X_train = st.transform(X_train)\n",
    "#     X_test = st.transform(X_test)\n",
    "    \n",
    "#     # Build Model\n",
    "    \n",
    "    \n",
    "#     X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1]))\n",
    "#     X_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1]))\n",
    "#     print(X_train.shape,X_test.shape)\n",
    "    \n",
    "    \n",
    "#     model = Sequential()\n",
    "# #     model.add(LSTM(32, batch_input_shape=(1,  X_train.shape[1], 1), stateful=True,return_sequences=True))\n",
    "#     model.add(LSTM(4, batch_input_shape=(1,  X_train.shape[1], 1), stateful=True))\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(loss = 'mean_squared_error',optimizer = 'adam')\n",
    "#     early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
    "#     model.fit(X_train, y_train, epochs=6, batch_size=1, verbose=1, callbacks=[early_stop], shuffle=False)\n",
    "    \n",
    "#     y_pred_train = model.predict(X_train,batch_size=1)\n",
    "#     y_pred_train = np.array([y_pred_train[i][0] for i in range(len(y_pred_train)) ])\n",
    "#     print(\"train RMSE Score is\",rmse(y_train,y_pred_train)) \n",
    "    \n",
    "    \n",
    "#     y_pred = model.predict(X_test,batch_size=1)\n",
    "#     y_pred = np.array([y_pred[i][0] for i in range(len(y_pred)) ])\n",
    "#     print(\"test RMSE Score is\",rmse(y_test,y_pred)) \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For LSTM\n",
    "\n",
    "test_df = test_df[cols_for_model]\n",
    "test_df = st.transform(test_df)\n",
    "\n",
    "demand_pred = model.predict(test_df,batch_size=1)\n",
    "demand_pred = np.array([demand_pred[i][0] for i in range(len(demand_pred))])\n",
    "\n",
    "sub_df[\"demand\"] = demand_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NN\n",
    "test_df = test_df[cols_for_model]\n",
    "demand_pred = nn_model.predict(test_df)\n",
    "demand_pred = np.array([demand_pred[i][0] for i in range(len(demand_pred))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[cols_for_model]\n",
    "test_df = st.transform(test_df)\n",
    "test_df = pd.DataFrame(test_df,columns = cols_for_model )\n",
    "demand_pred = xgm.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"demand_pred\"] = demand_pred\n",
    "sub_df[\"demand\"] = demand_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"sub_lstm_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[\"demand_pred\"] = glm.predict(st.transform(test_df)).astype(\"int\")\n",
    "# sub_df['demand'] = test_df['demand_pred']\n",
    "sub_df.to_csv(\"sub_glm.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
